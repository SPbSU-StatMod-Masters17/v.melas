\section{Теорема о числе опорных точек локально-оптимальных планов для Чебышевских систем}

Пусть у нас есть некоторая система Чебышева $\{u_i(t) \}_{i=0}^{p}$ на отрезке $[a,b]$. Рассмотрим множество всех возможных (непрерывных) планов $\Xi$, определенной следующим образом\footnote{При изучении Чебышевских систем мы предполагаем, что регрессия зависит  только от одного признака, поэтому вместо $x$ мы будем обозначать его за $t$}: 
\begin{align}
\Xi_k &= \left\{\begin{pmatrix}
        t_1 & … & t_k \\
        \nu_1 & … & \nu_k \\
\end{pmatrix}\right\} \\
\Xi &=  \bigcup \Xi_k
\end{align}

Вспоминаем, что информационная матрица плана выглядит следующим образом:
\begin{equation*}
M(\xi) = \int f(t)\Tr{f(t)}d\xi(t), \text{ где } \xi \in \Xi.
\end{equation*}

При этом $f$ — это частные производные функции $\eta(t, \theta)$ по $\theta$. Достаточно часто эти производные образуют систему Чебышева, а это сильно упрощает жизнь и позволяет получать различные хорошие аналитические результаты. Собственно матрица $M(\xi)$ является вектором в $\R^{\frac{m(m+1)}{2}}$, а ее элементы имеют вид:
$$M_{ij} = \int u_{ij}(t)d\xi(t), \xi \in \Xi.$$ 

Cуществует такое $n$, что любую $M(\xi)$ можно представать, как 
$$ M(\xi) = \int u d\xi(t), \xi \in \bigcup\limits_{i=1}^{n}\Xi_i, \text{ где } u=(u_0, …, u_p)$$
Докажем этот факт. 

\begin{dfn}
Моментным пространством $\mathcal{M}_{p+1}$ по отношению к $\{u_i\}_{i=0}^{p}$ называется множество 
$$\mathcal{M}_{p+1} = \{ \lambda c, c = (c_0, …, c_p) \in \R^{p+1}, \lambda \in \R_{+} | c_i = \int u_i(t)d\xi(t), \xi \in \Xi \}$$
\end{dfn}

Сечение этого конуса $\lambda = 1$ — это в точности всевозможные информационные матрицы планов.

Докажем, что любой  элемент $\mathcal{M}$ представим как выпуклая комбинация из $p+2$ точек кривой $C_{p+1}$
$$ С_{p+1} = \{ \gamma_t = (u_0(t), …, u_{p}(t)) | a\leq t \leq b\}.$$

Для этого нам нужно еще несколько обозначений.

Пусть $\mathcal{C}$ — наименьший выпуклый конус, содержащий кривую $C_{p+1}$. Рассмотрим множество $\Gamma$:
$$ \Gamma = \{ \gamma = (\gamma_0, …, \gamma_p), \gamma_i = \sum \limits_{j=0}^{p+2} \lambda_j u_i(t_j) \}, \text{ где}$$
$$ \lambda_j \geq 0, a \leq t_j \leq b$$

Это множество совпадает с $\mathcal{C}$. То, что $\Gamma \subset \mathcal{C}$ очевидно. Обратное утверждение следует из следующей теоремы:
\begin{thm}[Каратеодори]
Пусть $\mathcal{V} \subset R^{k}$ — ограниченное замкнутое множество. Тогда любой элемент его выпуклой оболочки может быть представлен в виде линейной комбинации не более, чем $k+1$ элементов этого множества.
\end{thm}

Докажем теперь, что $\mathcal{C} = \mathcal{M}_{p+1}$. По построению ясно, что $\mathcal{C} \subset \mathcal{M}_{p+1}$. Пусть теперь некоторый $\tilde{c} \in \mathcal{M}_{p+1}$, но $\tilde{c} \notin \mathcal{C}$. $\mathcal{C}$ является выпуклым замкнутым\footnote{Это вообще-то как-то не очевидно, а мы не доказывали. В книге Карлина используются неизвестные мне теоремы для док-ва…} конусом, поэтому по теоремам отделимости существует гиперплоскость, строго отделяющая $\tilde{c}$ от $\mathcal{C}$, т.е. существует такой вектор $a$ и $d \in \R$, что 
\begin{align}
\sum a_i \tilde{c}_i + d < 0 \\
\sum a_i \gamma_i + d \geq 0 \forall j \in \mathcal{C}
\end{align}
Из того, что $\gamma_i$ можно брать любым будет верно, что 
\begin{equation}
\label{eqal}
\sum a_i \lambda u_i(t) + d \geq 0 \forall t \in [a,b]
\end{equation}
Из последнего неравенства следует, что $d\geq 0$, иначе при $\lambda = 0$ неравенство будет неверным. 
Теперь рассмотрим $\sigma$, задающий $\tilde{c}$ (т.е. $\tilde{c} = \int u(t) d\sigma(t)$).  Пусть 
$\lambda = \int d\sigma(t) > 0$. Тогда с одной стороны
$$\sum a_i \tilde{c}_i + d = \int \sum a_i u_i d\sigma(t) + d  < 0$$
С другой, проинтегрировав \eqref{eqal} и поделив на $\lambda$ мы получим противоречие.
 

Теперь докажем теорему, которая, видимо, и имелась в виду в билете.
\begin{dfn}
Индексом точки $c \in \mathcal{M}_{p+1}$ называется такое минимальное $k$, что $c$ представима в виде выпуклой комбинации элементов $С_{p+1}$:
\begin{equation}
c = \sum \limits_{i=1}^{k} \lambda_i u(t_i)
\end{equation}
При этом точки $a$ и $b$ считаются за половину, а точки из $(a,b)$ за единицу.
\end{dfn}

\begin{thm}
$\tilde{c} \in \mathcal{M}_{p+1}$ является граничной точкой тогда и только тогда, когда $I(\tilde{c}) < \frac{p+1}{2}$. Кроме того, граничная точка $\tilde{c}$ допускает единственное представление
$$\tilde{c} = \sum\limits_{i=1}^{k}\lambda_i u(t_i), \text{ где } k \leq \frac{p+2}{2}, \lambda_i > 0$$
\end{thm}

{\color{blue} Я так и не понял, зачем мы рассматриваем конус (разве что из-за того, что так написано в книжке про чебышевские системы.) Теоремы отделимости работают и для выпуклых множеств, теорема Каратеодори сформулирована для выпуклой оболочки. Информационные матрицы для планов экспериментов также используют вероятностную меру. И вообще не уверен, что написанный текст соответствует вопросу…}