\section{Насыщенные локально D-оптимальные планы для экспоненциальных моделей с двумя параметрами}

В данном разделе мы будем изучать насыщенные локально $D$-оптимальные планы. Наша цель — доказать, что существует единственный насыщенный локально $D$-оптимальный план.

Производные данных моделей имеют вид:
$\{e^{-\lambda_i x}, -a_i x e^{-\lambda_i x} \}$
$$M(\xi, a, \lambda) = \int f(x)\Tr{f(x)}d\xi(x)$$

{ \color{blue} Объяснить через Бине-Коши, почему можно $a_i = 1$ взять }

Пусть
\begin{equation}
\begin{split}
 &F = (f(x_1), …, f(x_n)) \\
 & W = \diag(w_1, …,w_n) \\
 & \Tr{F} = \begin{pmatrix} \Tr{f(x_1)} \\ … \\ \Tr{f(x_n)} \end{pmatrix} 
 \end{split}
 \end{equation}

 Из последнего разложения видно, что определитель $\det M(\xi)$ можно посчитать по форумуле Бине-Коши.
 \footnote{$\forall A\in M_{n,m}\left(\R\right), B\in M_{m,n}\left(\R\right)$ $\mathrm{det}\left(AB\right)$ равен нулю, если $n<m$, и равен сумме попарных произведений соответствующих друг другу миноров порядка $m$, если $n\geqslant m$ (сумма берется по всем наборам столбцов матрицы $A$ и строк матрицы $B$ с возрастающими номерами $i_1<i_2<\ldots<i_m$).
 Миноры матриц $A$ и $B$ одинакового порядка, равного наименьшему из чисел $n$ и $m$, называются <<соответствующими>> друг другу, если они стоят в столбцах (матрицы А) и строках (матрицы В) с одинаковыми номерами.}
 Это позволит нам показать, что максимум определителя (по точкам $x_1, \ldots, x_n$) не зависит от значений параметра $a$.

 Мы будем изучать насыщенные планы. В таком случае число точек плана совпадает с числом параметров и задачи максимизации определителя $\det M(\xi)$ становится эквивалентна задачи максимизации $(\det F)^2$ (следует из теоремы \ref{sec9::thm::equal weights in D-opt plans for exp models} о том, что все веса в насыщенных локально $D$-оптимальных планах одинаковы). Для экспоненциальных система матрица $F$ имеет следующий вид:
 \begin{equation}
\Tr{F} = \begin{pmatrix} e^{-\lambda_1 x_1} & e^{-\lambda_1 x_2}   & … & e^{-\lambda_1 x_{2k}} \\
e^{-\lambda_2 x_1} & e^{-\lambda_2 x_2}   & … & e^{-\lambda_2 x_{2k}} \\ 
… & … & … & …\\
e^{-\lambda_k x_1} & e^{-\lambda_k x_2}   & … & e^{-\lambda_k x_{2k}} \\ 
-xe^{-\lambda_1 x_1} & -xe^{-\lambda_1 x_2}   & … & -xe^{-\lambda_1 x_{2k}} \\ 
… & … & … & …\\
-xe^{-\lambda_k x_1} & -xe^{-\lambda_k x_2}   & … & -xe^{-\lambda_k x_{2k}} \\ 
\end{pmatrix}
 \end{equation}
 Соответсвенно нам надо максимизировать $|\det \Tr{F}|$. Можно показать, что этот определитель совпадает с определителем матрицы\footnote{мы просто вынесли знак из столбцов с $x$ + воспользовались тем, что когда расскладывается по формуле Бине-Коши получается, что необходимо искать максимум  $(-1)^k\det F$, соответсвенно $(-1)^k$ сокращается с вынесенными из столбцов минусами.}
 \begin{equation}
 M(\xi, \lambda) = \Tr{\begin{pmatrix} e^{-\lambda_1 x_1} & e^{-\lambda_1 x_2}   & … & e^{-\lambda_1 x_{2k}} \\
e^{-\lambda_2 x_1} & e^{-\lambda_2 x_2}   & … & e^{-\lambda_2 x_{2k}} \\ 
… & … & … & …\\
e^{-\lambda_k x_1} & e^{-\lambda_k x_2}   & … & e^{-\lambda_k x_{2k}} \\ 
xe^{-\lambda_1 x_1} & xe^{-\lambda_1 x_2}   & … & xe^{-\lambda_1 x_{2k}} \\ 
… & … & … & …\\
xe^{-\lambda_k x_1} & xe^{-\lambda_k x_2}   & … & xe^{-\lambda_k x_{2k}} \\ 
\end{pmatrix}}
\end{equation}

Таким образом, мы решаем задачу
\begin{equation}
\label{maxEqExp}
xi^{*}(\lambda) = \argmax\limits{xi} \det M(\xi, \lambda)
\end{equation}
{\color{red}
Внимание! Чтобы в дальнейшем не вводить много новых обозначений, под $M(\xi, \lambda)$ будем понимать не саму матрицу, а ее определитель. Если будем необходима указать на матрицу, это будет явно сказано. Кроме того, не забывайте, что  выписана у нас не информационная матрица, а некоторый ее эквивалент с точки зрения $D$-оптимальности
}

Не умаляя общности будем считать, что $\lambda_1 > \lambda_2 > … > \lambda_k$.  Наша цель — заменить \eqref{maxEqExp} решение некоторого уравнения, имеющее единственное решение при любом  $\lambda$. В таком случае, при введенных на $\lambda$ ограничениях, решение также будет единственно.

Для этого нам потребуется несколько вспомогательных результатов.
\begin{lem}
Справедлива следующая формула
\begin{equation}
\begin{split}
&M(\xi, \lambda) =   \frac{1}{2! … (2k-1)!} e^{-d \sum\limits_{i=1}^{2k} x_i} \prod \limits_{1 \leq p < q \leq l} (\lambda_p - \lambda_q)^4 \prod \limits_{2k \geq i > l \geq 1} (x_i - x_j) \\
&\{ 1 - \frac{1}{2k} \left(\sum \limits_{j=1}^k( \lambda_j- d)\right) \left(\sum x_i\right) 
+ \frac{1}{2}\sum \limits_{j=1}^{k} (\lambda_j - d)^2 \frac{\sum x_i^2 (2k-1) - 2\sum \limits_{i\neq j} x_i x_j}{2k(2k-1)(2k+1)} + \\
&\frac{1}{2} \left( \sum (\lambda_j - d) \right) 
\frac{\sum x_i ^ 2 (2k-1) + 4k \sum\limits_{i \neq j} x_i x_j}{2k (2k-1)(2k+1)} + o(\alpha)\}
\end{split}
\end{equation}
где $\alpha = \max\limits_{i}(\lambda_i - d )^2$, $d$ произвольное вещественное число, $\frac{o(\alpha}{\alpha} \rightarrow 0$ при $\alpha \rightarrow 0$.
\end{lem}
\begin{proof}
Начнем с разложения следующей функции: $J(\theta) = \det || \exp(-\theta_i x_j)||_{i,j = 1}^{m}$. Разложим экспоненту в ряд:
$$ m_{ij} = \exp(-\theta_i x_j) = \sum\limits_{s=0}^{m+1} (-1)^{s}\frac{\theta_i x_j^{s}}{s!} + o((\theta_i x_j)^{m+1})$$ 
Заметим, что эта сумма — произведение двух векторов
$$m_{ij} = \Tr(1, \theta_i, \theta_i^2, …, \theta_i^{m+1}) \begin{pmatrix} (-1)^{0}\frac{x_j^0}{0!} \\ (-1)^{1}\frac{x_j^1}{1!} \\ … \\(-1)^{m+1}\frac{x_j^{m+1}}{(m+1)!} \end{pmatrix} $$

Таким образом, мы можем разложить экспоненты в $J$ в ряд и представить определитель как определитель произведения матриц $\det AB$, где $AB$ такие матрицы, что элементы их произведения равны $m_{ij}$. Определитель такого произведения можно вычислить с помощью формулы Бине-Коши и получить\footnote{Концептуально сложно ничего нету, элементарные (≠простые) вычисления.}:
\begin{equation}
\begin{split}
&\det ||\exp (-\theta_i x_j)|| = \frac{(-1)^{[m/2]} }{2!…(m-1)!}\det ||x_j^{s-1}||_{j,s = 1}^m \det ||\theta_{i}^{s-1}||_{i,s=1}^{m} + \\
& \frac{(-1)^{1+[m/2]} } {2!…(m-2)!(m)!}  \det||x_j^{s-1}||_{j=1…m, s = 1,…m-1, m+1}\det||\theta_{i}^{s-1}||_{i=1,…,m, s=1,…{m-1},m+1} + \\ 
& \frac{(-1)^{[m/2]} } {2!…(m-2)!(m+1)!}  \det||x_j^{s-1}||_{j=1…m, s = 1,…m-1, m+2}\det||\theta_{i}^{s-1}||_{i=1,…,m, s=1,…{m-1},m+2} +\\
& \frac{(-1)^{[m/2]} } {2!…(m-3)!(m-1)!(m)!}  \det||x_j^{s-1}||_{j=1…m, s = 1,…m-2, m+1}\det||\theta_{i}^{s-1}||_{i=1,…,m, s=1,…{m-2},m+1} +\\
&o\left( \max \limits_{r = 1…m}\theta_{r}^{\frac{(m+1)m}{2} + 1}\right)
\end{split}
\end{equation}
Входящие в эту сумму определитель можно вычислить явно:
Первый из них является определителем Вандермонда и равен:
$$\det ||x_j^{s-1}||_{j,s=1}^{m} = \prod \limits_{m \geq i > j \geq 1} (x_i - x_j)$$
Аналогично
$$\det ||\theta_j^{s-1}||_{j,s=1}^{m} = \prod \limits_{m \geq i > j \geq 1} (\theta_i - \theta_j)$$

Далее 
$\det ||x_j^{s-1}||_{j=1…m,s=1…m-1,m+1}$
является минором определителя 
$\det ||x_j^{s-1}||_{j,s = 1}^{m+1}$
Который, в свою очередь, можно разложить по соответствующей строке и получить
$$\det ||x_j^{s-1}||_{j,s = 1}^{m+1} = \sum\limits_{j=1}^{m+1} (-1)^{j+m} x_j^{m-1} \det ||x_i^{s-1}||_{i, s \in 1…m+1, i \neq j, s \neq m} = \prod\limits_{m+1 \geq i > j \geq 1}\left(x_i - x_j\right)$$
Приравняв коэффициенты при $x_{m+1}^{m-1}$ получим, что\footnote{Убедитесь в этом. Это как раз не сложно.}
$$\det ||x_j^{s-1}||_{j=1…m,s=1…m-1,m+1} = \sum\limits_{i=1}^{m}x_i \prod \limits_{m \geq i > j \geq 1}(x_i - x-j)$$
Аналогично , разложив определитель по двум строчкам, получим
$$\det ||x_j^{s-1}||_{j=1…m, s=1…m-1, m+2} = \left(\left(\sum\limits_{i=1}^m x_i\right)^2 + \sum\limits_{i\neq j}x_ix_j\right) \prod \limits_{m \geq i > j \geq 1}(x_i - x_j)$$
Воспользуемся формулой
$$2\sum\limits_{i\neq j} x_i x_j = \left(\sum x_i \right)^2 - \sum x_i^2, $$
подставим значения определителей и получим следующую формулу:
\begin{equation}
\label{determinantDecomposition}
\begin{split}
&J(\theta) = \prod \limits_{m \geq i >  j \geq 1}(x_j - x_i)(\theta_i - \theta_j) \frac{1-\sum\limits_{i=1}^{m}x_i\sum\limits_{j=1}^m\frac{\theta_j}{m}}{2!…(m-1)!} + \\
&\frac{1}{2} = \sum\limits_{i=1}^{m}(\theta_i^2)\frac{(m-1)\sum x_i^2 - 2\sum\limits_{i\neq j} x_i x_j}{m(m-1)(m+1)} + \\
& \frac{1}{2} (\sum \limits_{i=1}^{m}\theta_i^2) \frac{(m-1) \sum x_i^2 + 2m \sum\limits_{i \neq j} (x_i x_j)}{m(m-1)(m+1)}+ \\
& o(\max_{r} \theta_r^2)
\end{split}
\end{equation}
Теперь $M(\xi, \lambda) = \lim\limits_{\delta \rightarrow 0}\frac{J(\tilde{\lambda})}{\delta^k}$, где 
$\tilde{\lambda} = (\lambda_1, \lambda_1 + \delta, … , \lambda_k, \lambda_k + \delta$\footnote{В материале про рациональные модели аналогичный факт расписан более подробно, можно посмотреть там}.
Поэтому, взяв $m = 2k$ и $\theta = \tilde{\lambda}$ получаем утверждение леммы.
\end{proof}

\subsection{Экспоненциальные модели. Предельные планы.}
В процессе доказательства единственности локально-оптимальных насыщенных планов для экспоненциальной модели мы получим также один полезный результат о том, как будет выглядеть предельный план, когда все $\lambda_i$ одинаковы.

Докажем следующую вспомогательную лемму
\begin{lem}
\begin{itemize}
\item
Имеет место равенство
\begin{equation}
\lim \limits_{\lambda \rightarrow \lambda_d} \frac{M(\xi, \lambda)}{\prod\limits_{i < j}(\lambda_i - \lambda_j)^4} = \frac{1}{2!…(2k-1)!}\exp\left(-d\sum\limits_{i=1}^{2k}x_i\right)\prod\limits_{1 \leq i < j \leq 2k}(x_j - x_i)
\end{equation}
где $\lambda_d = \Tr{(d, d,…,d)}$, а $d$ является произвольным вещественным числом.

\item Определим функцию $\tilde{M}$
\begin{equation}
\tilde{M}(\xi, \lambda) = \frac{M(\xi, \lambda)}{\prod \limits_{i < j} (\lambda_i - \lambda_j)^4}
\end{equation}
Тогда функцию $\tilde{M}$ можно доопределить по непрерывности в точках $\lambda$  таких, что для некоторых $i$, $j$ будет выполнено $\lambda_i = \lambda_j$ 
\end{itemize}
\end{lem}
\begin{proof}
Первое утверждение следует из предыдущей леммы.

Второе утверждение — технические выкладки, аналогичные предыдущей лемме. Расскладываем для $\lambda = (\lambda_1, …, \lambda_{j-1}, d, …, d, \lambda_{j+s}, …,\lambda_{k})$ определитель на сумму произведения пар определителей с $(\lambda_1, …, \lambda_{j-1},  \lambda_{j+s}, …,\lambda_{k})$ и $(d, …, d)$. Далее определители с $(d, …, d)$ расскладываем аналогично лемме и получаем, что они непрерывны. У оставшихся слагаемых также не будет проблем с непрерывностью и предельным переходом доопределяем $\tilde{M}(\xi, \lambda)$.
\end{proof}


Таким образом мы можем рассматривать $\tilde{M}(\xi, \lambda)$ как непрерывную функцию на множестве $\Lambda = \{ \lambda \in \R^{k} | \lambda_i > 0\}$. 
\begin{dfn}
Оптимальной план-функцией будем называть отображение 
$$\xi^{*}(\lambda): \Lambda \rightarrow \mathbb{X}^{2k}, \mathbb{X} = (0, \infty)$$
удовлетворяющее при любом $\lambda \in \Lambda$
$$\tilde{\xi}^{*}(\lambda) = \max\limits_{\xi}\tilde{M}(\xi, \lambda)$$
\end{dfn}
Заметим, что оптимальная план-функция при любом фиксированном $\lambda \in \Lambda$  задает насыщенный локально $D$-оптимальный план. Как мы покажем далее, эта функция является единственной и локально $D$-оптимальный план определен единственным образом. 

Можно показать\footnote{без док-ва, можно посмотреть в статье в сборнике (доказывается, что $\frac{\partial}{\partial x_1} \det ||\exp(-x_i\theta_j)||_{i,j=1}^m < 0$)}, что 
$$\frac{\partial}{\partial x_1} \tilde{M}(\xi, \lambda) \leq 0$$
А значит точка $x_1 > 0$ не может быть точкой локального экстремума функции $\tilde{M}(\xi, \lambda)$, а значит $x_1^{*}(\lambda) = 0$. 

Нам потребуется еще один вспомогательный результат
\begin{lem}
Значение $\xi^{*}(\lambda)$ в точке $\lambda_d$ ($\lambda_d = \Tr{(d, d,…,d)}, d > 0$)  определено единственным образом и 
$\xi(\lambda_d) = (0, \gamma_2, …, \gamma_{2k})$, где $\gamma_i = \frac{2\gamma_{i-1}'}{d}$. Точки $\{ \gamma_i' \}_{i=1}^{2k-1}$ являются корнями многочлена Лагерра с параметром $\alpha = 1$ $L_{2k-1}^1(x)$.  
\end{lem}
\begin{proof}
Без доказательства
\end{proof}
Последняя лемма и есть предельный план для экспоненциальной модели. 

\subsection{Основное уравнение функционального подхода для экспоненциальной модели}
{\color{blue} сюда также надо добавить информацию из \ref{funcApproach}. Мы рассматривали функциональный подход в применении к экспоненциальным моделям, но на самом деле он ими не ограничивается. Более общее изложение можно найти в пособии, либо в книге Functional Approach to optimal experimantal design. 
Через library.spbu.ru есть доступ к некоторым книжкам springer в электронном виде, в том числе и к этой}
Мы хотим свести задачу поиска оптимального плана к задаче поиска неявной функции. Предыдущие леммы позволяют нам сформулировать задачу поиска оптимального плана как решение следующей системы:
\begin{equation}
\label{functionalExpModel}
\begin{split}
&x_1^{*}(\lambda)=0 \\
&\frac{\partial}{\partial x_i}\tilde{M}(\xi^{*}(\lambda), \lambda) = 0, i = 2…2k \\
& 0 < x_2^{*}(\lambda) < … < x_{2k}^{*}(\lambda)\\
\end{split}
\end{equation}
Строгое неравенство для точек плана следует из того, что если есть хотя бы две совпадающие, то определитель (которому равносильна $\tilde{M}$) обращается в ноль. 

Полученная система задает оптимальный план $\xi^{*}(\lambda)$ неявным образом. Для того, чтобы воспользоваться теоремой о неявной функции нам нужны некоторые хорошие свойства от якобиана данной системы. Более того, для того, чтобы план был локальным максимумом целевой функции необходимо, чтобы  
якобиан был отрицательно-определенным. 
\subsection{Структура матрицы Якоби}
Для рассматриваемой нами функции это будет действительно верно:
\begin{thm}
Матрица $\{ \frac{\partial^2}{\partial x_i \partial x_j} \tilde{M}(\xi^{*}(\lambda), \lambda)\}$, где $\xi^{*}$ удовлетворяет \eqref{functionalExpModel}, а  $\lambda \in \Lambda$ является отрицательно определенной.
\end{thm}

\begin{proof}
Будем считать, что $\xi^{*}$ имеет вид $(x_1, …, x_{2k})$, $0 \leq x_1 < … < x_{2k}$.  Для начала докажем, что если 
$\frac{\partial}{\partial x_i} \tilde{M}(\xi,\lambda)=0$ для некоторого фиксированного $i=2…2k$, то 
$$\frac{\partial^2}{\partial x_i^2} \tilde{M}(\xi, \lambda) < 0$$
Не умаляя общности считаем, что $i=2$. 
Положим $g(z) = \frac{\partial}{\partial z}\tilde{M}(x_1,z, x_2, …, x_{2k}, \lambda)$. 

{\color{red} тут ошибки с индексами. надо все аккуратно проверить и переписать. }
Далее $\tilde{g}(z) = \tilde{M}(x_1,z, x+2 …, x_{2k}, \lambda)$ обращается в ноль в точках $x_1, x_3, …, …, x_{2k}$. 
Из того, что $\tilde{g(z)}$\footnote{это определитель неотрицательно-определенной матрицы} больше нуля получаем, что $g(z)$ равно нулю на интервалах\footnote{Между корнями непрерывной функции есть корень производной}$(x_1, x_2)$, $(x_{3}, x_{4})$, $(x_{4}, x_{5})$, …,$(x_{2k}, \infty)$ 
, а также $g(x_i) = 0$. Утверждение про корень на $(x_{2k}, \infty)$ следует из того, что $\tilde{g}(z) \rightarrow 0$ на бесконечности.
 В тоже время, разложим $\tilde{M}$ по столбцу\footnote{или по строчке, если я строчки и столбцы перепутал} можно получить, что 
$$g(z) = \sum_{i=1}^k a_i \exp(-\lambda_i z) + b_i z \exp(-\lambda_i z)$$
Значит $g(z)$ является обобщенным многочленном и по свойству систем чебышева\footnote{экспоненциальная система, как все помнят, к ним относится} получаем, что $g(z)$ имеет не более $2k-1$ нуля с учетом кратности.  Следовательно $x_i$ не может быть нулем кратности 2 и более. Далее $\tilde{g}(z)$ обращается в ноль при $z=x_{i-1}, x_{i+1}$, а внутри интервала строго больше нуля. Значит $g(z)$ имеет единственный нуль при $z \in (x_{i-1}, x_{i+1}$. Следовательно $x_i$ есть точка локального максимума функции $\tilde{g}$ и 
$$\frac{\partial^2}{\partial x_i^2}\tilde{M}(\xi, \lambda) < 0$$

Теперь если $\xi, \lambda$ таковы, что 
$$\frac{\partial}{\partial x_i} \tilde{M}(\xi, \lambda) = 0$$
при некотором фиксированом $i=2…2k$, то
$$\frac{\partial^2}{\partial x_i x_j} \tilde{M}(\xi, \lambda) > 0 $$
при любом $i \neq j$. 

Не умаляя общности считаем, что $i=2, j=3$. Тогда  
Положим $g(z) = \frac{\partial}{\partial x_i}\tilde{M}(x_1,x_2, z, x_2,…, \lambda)$. $g(x_i)=0$ при $i \neq 2$, т.к. в определителе будут две совпадающие строчки. По условию $g(x_j) = 0$. 

Далее при $z \rightarrow \infty$ $g(z)$ стремится к нулю (один из столбцов стремится к нулю). 
 Получаем, что $g'(z)$ обращается в ноль на интервалах $(x_1, x_2), (x_3, x_4), …, (x_{2k-1}, x_{2k}), (x_{2k}, \infty)$. 
 Аналогично предыдущему получаем, что $g'(x_l)$ обращается в нуль на $(x_1, x_2)$, $(x_3, x4)$,…,$(x_{2k}, +\infty)$. 
 По чебышевскому свойству получаем (после подсчета нулей), что $g'(x_j) \neq 0$. 
Далее можно показать что 
$$\text{sgn} g'(z)|_{z = x_j} = \text{sgn} g(x_j) (-1)^{j-i+1}j$$
где $h = 1$ если $j<i$ и $-1$ иначе.
Плюс 
$$hg(x_j)(-1)^{j-i+1} = \lim\limits_{\delta\rightarrow 0}\frac{\tilde{M}(x_1, …, x_i, x_i + \delta, x_{i+1}, …, x_{j-1}, x_{j+1}, …, x_{2k}, \lambda)}{\delta}$$
Можно показать, что $\tilde{M}(\xi_\delta, \lambda) > 0$ при $\delta\in(0, x_{i+1}-x_{i}$, следовательно $g'(x_j) \geq 0$. За счет того, что $g'(x_j) \neq 0$ получаем, что 
$$\frac{\partial^2}{\partial x_i \partial x_j} \tilde{M}(\xi, \lambda) = g'(x_j) > 0$$

{\color{red} в общем идея в предыдущем понятная, но с индексами беда. + кажется ошибки в статье с обозначениями.}

Теперь докажем следующее тождество:
\begin{equation}
\sum \limits_{i=1}^{2k} \frac{\partial }{\partial x_i} \tilde{M}(\xi, \lambda) = -2 (\sum \lambda_i)\tilde{M}(\xi, \lambda)
\end{equation}
\begin{equation}
\begin{split}
&\det||e^{-\lambda_1(x_i+\delta), (x_i+\delta)e^{-\lambda_1+\delta}, …, e^{-\lambda_k(x_i+\delta)}, (x_i+\delta)e^{-\lambda_k(x_i+\delta)}}||_{i=1}^{2k} = \\
&\exp\left(-2\sum\lambda_i \delta\right) \det||e^{-\lambda_1 x_i}, x_ie^{-\lambda_1 x_i}, …, e^{-\lambda_k x_i},x_ie^{-\lambda_kx_i}||\\ 
\end{split}
\end{equation}
Продиффиренцируем последнее равенство по $\delta$ и воспользуемся тем, что 
$$ 
 \frac{\partial}{\partial \delta} \tilde{M}(\xi_\delta, \lambda)  = \sum \frac{\partial}{\partial x_i} \tilde{M}(\xi_\delta, \lambda)$$
 получим требуемое.

Воспользовавшися доказанным тождеством получаем, что для любого $\lambda$
$$ \frac{\partial}{\partial{x_j}} \sum\limits_{i=1}^{2k} \frac{\partial}{\partial x_i}\tilde{M}(\xi^{*}(\lambda), \lambda) = -2 (\sum\lambda_i)\frac{\partial}{\partial x_j}\tilde{M}(\xi^{*}(\lambda), \lambda)$$
где $\xi^{*}$ — любое оптимальная план-функция (решение уравнения, задающего неявную функцию).

В итоге в $(\xi^{*}, \lambda)$ имеем 
$$\sum\limits_{\substack{i=1…2k \\ i \neq j}}   | \frac{\partial^2}{\partial x_i \partial x_j} \tilde{M}| = \sum \frac{\partial^2}{\partial x_i \partial x_j} \tilde{M} = -\frac{\partial^2}{\partial x_j^2} \tilde{M}$$  
Далее
$$ \sum\limits_{i =2 …2k, i \neq j} | \frac{\partial^2}{\partial x_i \partial x_j} \tilde{M}| < |\frac{\partial ^2 }{\partial x_j^2}\tilde{M}| \leq
|\frac{\partial ^2 }{\partial x_j^2}\tilde{M} - \mu|$$
где $\mu \geq 0$.
Отсюда по критерию Адамара $\det (P - \mu I) \neq 0$
где $P = \{  \frac{\partial^2}{\partial x_i \partial x_j} \tilde{M} \}_{i,j=2}^{2k}$. 
Матрица $P$ симметричная, поэтому все собственные числа вещественны и  из произвольности $\mu$ они все должны быть отрицательными (иначе выберем такое $\mu$, что определитель равен нулю. Получим противоречие критерию Адамара)
Кроме того $P^{-1}$ состоит из отрицательных элементов.
\end{proof}

Благодаря этой теореме мы можем применить теорему о неявной функции. 
Для любой точки $\lambda \in \Lambda$ существует окрестность $W(\lambda)$  в которой \eqref{functionalExpModel} $\xi^{*}$ задает неявную функцию 
$\xi^{*}(\lambda)=(0, x_2^{*}(\lambda),…)$, т.е.  
$$\xi^{*} = \xi^{*}(\lambda) \Leftrightarrow \frac{\partial}{\partial x_i}\tilde{M}(\xi^{*}(\lambda), \lambda)=0$$
Теорема о неявной функции также дает нам, что $\xi^{*}$ непрерывна и определена единственным образом в данной окрестности.


\subsection{Теорема о единственности насыщенных локально D-оптимальных планов для экспоненциальных моделей}
Теорема о неявной функции дает единственность только локально (в окресности каждой точки $(x_1, …, x_{2k}, \lambda_1,…,\lambda_{k})$). Докажем теперь, что единственность будет глобальной.

\begin{lem}
Пусть $W$ — окрестность точки, в которой определена $\xi^{*}(\lambda)$. Тогда $x_{i}^{*}(\lambda)$ для $i=2…2k$ строго-моннотоно убывает по каждому $\lambda_{j}$ ($\lambda \in W$).
\end{lem}
\begin{proof}
Без док-ва\footnote{Для док-ва надо получить, что $\frac{\partial^2}{\partial \lambda_i \partial x_j}\tilde{M} > 0$ и воспользоваться тем, что элементы $P^{-1}$ из теоремы о структуре матрицы Якоби будут отрицательными.}
\end{proof}

{ \color{blue} тут надо доказать факт про то, что функцию $\xi^{*}(\lambda)$ можно доопределить на множестве $\Lambda_{\lambda'} = \{\lambda \in \R^k | \lambda_i \geq \lambda' \}$, если $\xi^{*}$ была изначально задана в окрестности $\lambda'$ }
\begin{lem}
Решение системы \eqref{functionalExpModel} единственно для любого $\lambda \in \Lambda$.
\end{lem}
\begin{proof}
Пусть это не так. Значит существует $\lambda'$ и $\xi_1$ и $\xi_2$ такие, что 
$$\frac{\partial}{\partial x_i} \tilde{M}(\xi, \lambda') = 0 (i = 2…2k)$$
где последнее выражение верно для $\xi = \xi_1$ и $\xi=\xi_2$.
За счет предыдущих лемм можно определить $\xi_1(\lambda)$ и $\xi_2(\lambda)$ — непрерывные вектор-функции на множестве $\Lambda = \{ \lambda: \lambda_i \geq\lambda_i'\}$ такие, что
$$\xi_1(\lambda')=\xi_1$$
$$\xi_2(\lambda')=\xi_2$$
$$\frac{\partial}{\partial x_i} \tilde{M}(\xi_i, \lambda) = 0$$
и $\xi_{i}(\lambda)$ задает план ($\xi = (0, x_2, …, x_{2k}$, $0 < x_2 < … < x_{2k}$).
Теперь рассмотрим $\lambda_d = (d, …, d)$, где $d = \max(\lambda_{i}')$. В этой точке функции совпадают. Кроме того, они непрерывны. Следовательно существует точка $\tilde{\lambda}$ такая, что в ее окрестности заданы две несовпадающие вектор-функции $\xi_1(\lambda)$ и $\xi_2(\lambda)$, а в самой точке $\xi_1(\tilde{\lambda}) = \xi_2(\tilde{\lambda})$. Получаем противоречие с единственностью из теоремы о неявном отображении.
\end{proof}

Также верна следующая лемма:
\begin{lem}
Функции $\xi_i^{*}(\lambda)$ являются аналитическими при $\lambda \in \Lambda$
\end{lem}

В итоге мы пришли к следующей теореме:
\begin{thm}
Оптимальная план-функция существует и определена единственным образом. Первая точка плана $x_1$ находится в нуле, поэтому ее можно рассматривать как функцию $\xi{\lambda} : \Lambda \rightarrow [0, \infty)^{2k-1}$. Кроме того, координатные функции являются аналитическими и строго убывают по каждому $\lambda_j$. План $\xi(\lambda)$ является насыщенным $D$-оптимальным при любом фиксированном $\lambda: \lambda_1 > \lambda_2 … > \lambda_k$.
\end{thm}



