\section{E-оптимальные планы}
\subsection{Определение и статистический смысл}
Пусть $M(\xi)$ — информационная матрица плана. 
\begin{dfn}
Будем говорить, что план $\xi$ является $E$-оптимальным, если 
$$ \xi = \argmin\limits_{\lambda_{\min}(M(\xi))}, \text{ где}$$
$\lambda_{\min}(M(\xi))$ — минимальное собственное число $M(\xi)$. 
\end{dfn}
Статистический смысл этого критерия состоит в минимизации дисперсии следующего выражения:
$$D(\Inner{p}{\theta}), \text{ где } p \in \R^m, ||p||_2 = 1$$
$$D(\Inner{p}{\theta}) = \Tr{p}M^{-1}(\xi)p$$
Из последней формулы видно\footnote{вспоминаем линейную алгебру и то, что $M^{-1}$ является положительно-определенной матрицой}, что максимум этого выражения достигается на первом собственном векторе, а cам максимум равен первому собственному числу. Собственные числа $\frac{1}{\lambda_i}$ матрицы $M^{-1}$ совпадают с обратными к  $\lambda_i$ — собственным числам матрицы $M$. Из такого представления следует, что $E$-оптимальность означает минимизацию максимальной длины оси доверительного эллипсоида для МНК-оценки\footnote{Эта ось, как все помнят, совпадает с направлением первого собственного вектора матрицы $D(\theta)$.}.


{\color{blue} что сюда еще надо?}
\subsection{Теорема эквивалентности}
\begin{dfn}
Обозначим класс неотрицательно-определенных симметричных матриц с единичным следом за $\mathbb{A}$. 
$$\mathbb{A} = \{ A | A \text{ p.s.d.}, \trace{A} = 1 \}$$
\end{dfn}
\begin{thm}
Пусть $f(x)=\Tr{(f_1(x), …, f_n(x)}$, $x \in \mathbb{X}$ является непрерывной функцией. Тогда:
\begin{enumerate}
\item План $\xi^{*}$ является $E$-оптимальным тогда и только тогда, когда 
$$\exists A^{*} \in \mathbb{A} \max\limits_{x \in \mathbb{X}} \Tr{f(x)}Af(x) \leq \lambda_{\min}(M(\xi^*)$$
\item $$\Tr{f(x_i^*)}A^{*}f(x_i^*) = \lambda_{\min}(M(\xi^*)), \text{ где}$$
для $i=1…n$ $x_i^*$ являются опорными точками $E$-оптимального плана.
\item $$ \min\limits_{A}\max\limits_{x \in \mathbb{X}} \Tr{f(x)}Af(x) = \max\limits_{\xi}\lambda_{\min}M(\xi)$$
\end{enumerate}
\end{thm}


Эта теорема является следствием общей теоремы о минимаксе.
\begin{thm}[фон-Неймана о минимаксе]
Пусть $f(x,y)$, $x\in \Omega_1, y\in \Omega_2$. $f(x,y)$ выпукла по $x$, вогнута по $y$. $\Omega_1, \Omega_2$ выпуклые и хотя бы одно компактно, $f$ непрерывна. Тогда 
$$ \min\limits_{x \in \Omega_1} \max\limits_{y \in \Omega_2} f(x,y) = \max\limits_{y \in \Omega_2} \min\limits_{x \in \Omega_1} f(x,y)$$
\end{thm}

Далее перепишем задачу на поиск минимального собственного числа информационной матрицы плана:
 $$\lambda_{\min}(M) = \min \limits_{||p||=1} \Tr{p}Mp$$
  Пусть $p_i$ — ортонормированный базис. Тогда 
$$p \sum \sqrt{\alpha_i} p_i$$
$$ \sum \alpha_i = 1$$
Отсюда 
\begin{equation}
\begin{split}
&\min \limits_{||p||=1} \Tr{p}Mp = \sum \limits_{i=1}^m \alpha_i\Tr{p_i}Mp_i \\
&\trace (M \sum \alpha_i p_i \Tr{p_i}) = \trace{MA}
\end{split}
\end{equation}
где $A = \sum \limits_{i=1}^m \alpha_i p_i\Tr{p_i}. \trace{A} = 1$. Таким образом в старых обозначениях:
$$\lambda_{\min}(M) = \min \limits_{A \in \mathbb{A}} \trace{MA}$$

Теперь объединим предыдущее разложение и теорему об минимаксе:
$$\lambda_{\min}M(\xi) = \min_{||p||=1}\Tr{p}M(\xi)p = \min_{A \in \mathbb{A}} \trace{AM}$$
Нам интересна $E$-оптимальность и поэтому промаксимизируем по всем планам. Пусть $\mathbb{M} = \{ M(\xi) \}$ — множество информационных матриц планов (оно выпуклое и компактное). Таким образом\footnote{Мы воспользовались тем, что $\trace{AB}$ является линейной выпокло-вогнутой фнукцией. Кроме того при переходе от
$\max\trace{A\sum f(x_i)\Tr{f(x_i)}w_i}$ использовалось то, что максимум выпуклой сумма положительных слагаемых не превосходит максимального из них}:
\begin{equation}
\begin{split}
&\max\limits_{\xi}\min\limits_{A}\trace{AM} = \max{M \in \mathbb{M}}\min\limits_{A \in \mathbb{A}} = \\
&\min\limits_{A \in \mathbb{A}}\max\limits_M\trace{AM} = \min\limits_{A}\max\limits_{\xi}\trace{A\sum f(x_i)\Tr{f(x_i)}w_i} = \min\limits_{A}\max\limits_{x}\Tr{f(x)}Af(x)
\end{split}
\end{equation}

Выкладка про то, что из минимакса следует эквивалетность:
$$ \min\limits_{A} \max\limits_{X} \leq \Tr{f}A^{*} f \leq \lambda_{\min}M(\xi) \leq \max\limits_{\xi}\lambda_{\min}M(\xi)$$
Последнее и первое по теореме о минимаксе равны.

$$ \eta(x, \theta) = \alpha_0 + \sum\limits_{i=1}^k \alpha_i \sin(x) + \beta_i \cos(x) + \varepsilon$$
Параметры входят линейно и $f(x) = \Tr{(1, \sin x, \cos x, …, \sin kx, \cos kx)}$, где $x \in [0, 2\pi]$.  

\begin{thm}
$E$-оптимальным планом для тригонометрической модели является 
$$ \xi^{*} = \left\{ \frac{2\pi(i-1)}{n}, i = 1…n\right\}$$
c весами $\frac{1}{n}$, где $n \geq 2k + 1$.
Матрица $M(\xi) = \diag(1, \frac{1}{2}, …, \frac{1}{2})$
\end{thm}
\begin{proof}
Рассмотрим $A^{*}=\diag(0,\frac{1}{2k}, …, \frac{1}{2k}$
$$\Tr{f}A^*f = \sum\limits_{j=1}^k \left(\frac{sin^2 jx + cos^2jx}{2k}\right)= k \frac{1}{2k} = \frac{1}{2}$$
Следовательно $\max\limits_x \Tr{f(x)}A^{*}f(x) = \frac{1}{2}$. Отсюда по теорем эквивалентности $M(\xi) = \diag(1, \frac{1}{2}, …, \frac{1}{2})$ является матрицей оптимального плана. 

Оптимальный план будет в точках $\{ \frac{2\pi(i-1)}{n}\}$. {\color{blue} как это выводится не ясно, но то, что результат будет тем, что надо кажется достаточно известный факт.}. 
{\color{blue} Как, кажется, можно доказать: берем какую-то из сумм вида $\sum w_k \sin\frac{2\pi(i-1)s}{n} \cos\frac{2\pi(j-1)s}{n}$. Если все веса одинаковы, то после какой-то перегруппировки тут будет сумма $a$ и $-a$. Для диагонали, наоборот, будет сумма $\sin^2(x) + \cos^2(x)$ которые будут давать 1. Но это надо аккуратно проверять.} 
\end{proof}

\begin{note}
$E$-оптимальный план не обязательно единственный. 
\end{note}

\subsection{Теорема о структуре матрицы из условия эквивалентности.}
\begin{thm}
В условия теоремы эквивалентности:
$$ A^{*} = \sum \limits_{i=1}^s \alpha_i p_i \Tr{p_i}$$
где $p_1, …, p_s$ —  ортонормированный базис, $\alpha_i >0$, $\sum\alpha_i = 1$. 
$s$ равно кратности минимального собственного числа.
\end{thm}
\begin{proof}
$A^*$ — неотрицательно-определенная матрица. Следовательно существует ортонормированный базис из собственных векторов. Выберем его так, что первые $s$ векторов соответствуют минимальному собственному числу $M$. Тогда для любого $p$:
\begin{equation}
\begin{split}
&p = \sum \alpha_i p_i \\
&A^{*} = \sum \alpha_i p_i \Tr{p_i}  = \sum\limits_{i=1}^{s} \alpha_i p_i \Tr{p_i} + \sum\limits_{i=s+1}^m \alpha_i p_i \Tr{p_i}\\
&\max\limits_x\Tr{f(x)} A^{*} f(x) = \max\limits_{x}\trace{\sum\limits_i  \alpha_i \Tr{p_i} f(x)\Tr{f(x)} p_i} \\
& = \max\limits_{\xi}\trace{A M(\xi)} = \max \limits_{\xi}\trace{\sum \alpha_i \Tr{p_i}Mp_i} \\
\trace{\sum \alpha_i \Tr{p_i}Mp_i} = \trace{\sum \alpha_i \lambda_i}
\end{split}
\end{equation}
Смотрим на последние два равенство. В последнем мы воспользовались тем, что $p_i$ собственные вектора $M$. Далее т.к. $a_i$ задают выпуклую комбинацию, то минимум достигается, если не нулевые $\alpha_i$  будут только среди тех коэффициентов, которые стоят передем минимальным собственным числом, что нам и требовалось.
\end{proof}

\begin{note}
Рассмотрим частный случай $s=1$. Тогда $A = p \Tr{p}$. 
$$\max\limits_{x} f(x) p \Tr{p} f(x) \leq \lambda_{\min}$$
Что тоже самое, что 
$$\max\limits_{x} (\Tr{p}f(x))^2 \leq \lambda_{\min}$$
\end{note}

\subsection{Теорема о числе опорных точек в E-оптимальных планах для полиномиальных моделей.}
Рассмотрим полиномиальную модели:
\begin{equation}
\eta(x,\theta)  = \Tr{\theta}f(x), x \in [a,b]
\end{equation}
где
$$\theta = \Tr{(\theta_0, …, \theta_{m-1})}  \in \mathbb{\Theta}$$
$$f(x) = \Tr{(1, x, …, x^{m-1})}$$

\begin{thm}
Пусть $m > 2$. Тогда существует единственный $E$-оптимальный план с $m$-опорными точками, две из которых совпадают с граничными точками.
\end{thm}
\begin{proof}
Пусть $\xi^* = \begin{pmatrix} x_1 & … & x_n \\ w_1 & … & w_n \end{pmatrix}$ — оптимальный план. Тогда по теореме эквивалентности $\exists A^{*}$ такое, что $=$
\begin{equation}
\Tr{f(x)}A^{*}f(x) \leq \lambda_{\min} \\
\Tr{f(x_i)}A^{*}f(x_i) \leq \lambda_{\min}
\end{equation}

\begin{equation}
\begin{split}
g(x) = \Tr{f(x)}A^{*} f(x) - \lambda_{\min} \\
g(x) \leq 0
\end{split}
\end{equation}

$g(x)$ является полиномом степени $2n-2$. При этом у него имеется по крайне мере $n$ корней на $[a,b]$. За счет того, что полином не может стать больше, внутренние корни должны иметь кратность $2$. Далее на бесконечностях полином стремится к $+\infty$ или $g(x) =0$. Пусть на бесконечности полином стремится к $+\infty$. Тогда у $g(x)$
будет по крайне мере  $2(n-2)+2$ нуля в случае, когда будет по точке на краях. В противном случае степень полинома будет больше и такая ситуация не возможна.  
Существование нескольких решений возможно только в случае, когда $g(x) = const$\footnote{Кажется при этом мы пользуемся тем, что матрица $A^{*}$ задает единственное решение. На момент рассмотрения этой теоремы мы этого не доказывали. Однако в дальнейшем у нас будет теорема о простоте собственного числа для полиномиальных моделей, что автоматически дало бы единственность  $A^{*}$. Но там был симметричный отрезок $[-1,1]$. Как доказать эту теорему, не ссылаясь на факт из следующего вопроса, не ясно.} 
Пусть $g(x) = const$. Тогда $\Tr{f}A^{*}f = \sum b_i x^i$,  где все $b_i$, кроме $b_0$ равны нулю. Таким образом, получаем, что\footnote{квадратичная формула обнуляется на всех векторах, кроме первого орта. Отсюда следует, что все элементы матрицы, кроме (1,1) должны быть нулем. Это не очень сложное упражнение по линейной алгебре, которое скорее всего неоднократно доказывалось.} 
$$ A^{*} = \begin{pmatrix} 1 & 0 & … & 0 \\ 0 & 0 & … & 0 \\ … & … & … & … \end{pmatrix}$$
$$A^{*} = e_1 \Tr{e_1}$$
Следовательно $Me_1 = \lambda e_1$ (пользуемся теоремой о структуре матрицы из условия эквивалентности). При этом матрицу $M$ мы можем вычислить:
$$ M = \begin{pmatrix} 1 & \sum w_ix_i & \sum w_ix_i^2 & … \\ \sum w_i x_i & … & … & …\\  … & … & … & … \end{pmatrix} $$

Ситуация, когда $Me_1 = \lambda e_1$ возможна только для $m=1,2$. Таким образом, для $m > 2$ решение единственно. 
\end{proof}

\subsection{Теорема о E-оптимальных планах для линейной модели на произвольном отрезке}
Рассмотрим линейнуюю модель\footnote{Является исключением из предыдущего пункта $m=2$} $\eta(x, \theta) = \theta_0 + \theta_1 x$, $x \in r_1,r_2]$. 
\begin{thm}
\begin{enumerate}
\item Если $r_1r_2 \geq -1$, то $\xi = \begin{pmatrix} r_1 & r_2 \\ w_1 & w_2\end{pmatrix}$, где 
$$w_1 = \frac{2+r_1^2 + r_1r_2}{4+(r_1+r_2)^2}$$
$$ w_2 = \frac{2+r_1^2 + r_1r_2}{4+(r_1+r_2)^2}$$ 
\item Если $r_1r_2 < -1$
$$\xi_{a,b} = \begin{pmatrix} a & b \\ \frac{b}{b-a} & \frac{-a}{b-a} \end{pmatrix}$$
где $r_1 \leq a < 0$, $0 < b \leq r_2$, $|ab|> 1$
\end{enumerate}
\end{thm}
\begin{proof}
$$ M = \begin{pmatrix} 1 & w_0 x_0 + w_1 x_1 \\ w_0 x_0 + w_1 x_1 & w_0 x_0^2 + w_1 x_1^2 \end{pmatrix}$$
$$ a \frac{b}{b-a} + b \frac{-a}{b-a} = 0$$
$$ a^2 \frac{b}{b-a} + b^2 \frac{-a}{b-a} = -ab$$
Следовательно: 
$$M(\xi_{a,b}) = \begin{pmatrix} 1 & 0 & 0 & -ab \end{pmatrix}$$

Собственные числа матрицы
$$\begin{pmatrix} 1 & c \\ c & d \end{pmatrix}$$ 
равны
$$lambda_1 = 1/2 (-sqrt(4 c^2+d^2-2 d+1)+d+1)$$
$$ lambda_2 = 1/2 (sqrt(4 c^2+d^2-2 d+1)+d+1)$$
Совпадают они только в случае, когда $c=0$ и $d=1$. 
Если $d$ фиксировано, то максимальное $\lambda_{\min}(M)$ будет достигаться при $c = 0$. При $c=0$ минимальным собственным числом будет 1, если $d>1$. Если $d< 1$, то этим собственным числом будет $d$. Мы хотим максимизировать минимальное собственное число, а значит нам нравится вариант $d\geq 1$. При сформулированных в теореме условиях это будет выполнено. Отсюда получаем, что для $r_1r_2 < -1$ у нас есть много оптимальных планов.

Теперь рассмотрим случай $r_1r_2 \geq -1$. Предположим, что минимальное собственное число информационной матрицы оптимального плана имеет единичную кратность. Тогда
$$A^{*} = q\Tr{q}$$
где  $q$ собственных вектор $M$, $||q|| = 1$.
Матрица $M(\xi) = f(r_1)\Tr{f(r_1)}w + f(r_2)\Tr{f(r_2)}(1-w)$ 

Будем искать $q$ в виде $\Tr{(1, q_1)}$. Тогда, если $r_1$ и $r_2$ точки плана, то
$$ 1 + q_1r_1 = ±\sqrt{\lambda_{\min}}$$
$$ 1 + q_1r_2 = ±\sqrt{\lambda_{\min}}$$
Из уравнения видим, что в уравнения не могут давать один знак, поэтому сложим их и получим:
$$2 + q_1(r_1+r_2)=0$$
$$q_1 = \frac{-2}{r_1+r_2} = -\frac{1}{\mu}$$
Проверим, что такой $q$ является собственным вектором:
\begin{equation}
\label{eigeq}
\left(f(r_1)\Tr{f(r_1)}w + f(r_2)\Tr{f(r_2)}(1-w)\right)q = \lambda q
\end{equation}
Пусть 
$$ 1 + r_1 q_1 = -h$$
$$ 1 + r_2 q_1 = h = 1 - \frac{r_2}{\mu}$$ 
Тогда \eqref{eigeq} можно записать в виде
$$ f(r_1) h w + f(r_w)(-h)(1-w) = \lambda \begin{pmatrix} 1 \\ -\frac{1}{\mu} \end{pmatrix}$$
Подставляем и получаем\footnote{Мы можем считать, что $w$ у нас есть в условии доказываемой теоремы, но он также получается и просто из системы. После того, как $w$ найден, поиск $\lambda$ сводится к подстановке и алгебраическим манипуляциям}
$$ \lambda = (2w - 1)h = \frac{r^2}{r^2 + \mu ^2}$$ 
где $r = \frac{r_2 - r_1}{2}, \mu = \frac{r_2+r_1}{2}$

Можно проверить\footnote{вычислив собственные числа матрицы}, что найденное $\lambda$ будет с.ч. кратности 1, что дает нам оптимальность (по теореме эквивалентности).
 \end{proof}

 \subsection{Теорема о E-оптимальных планах для квадратичной модели на симметричном отрезке}
 Рассмотрим $\eta(x,\theta) = \theta_0 + \theta_1 x + \theta_2 x^2 + \varepsilon, x \in [-r, r]$. 
 \begin{thm}
 Для квадратичной регрессии на симметричном промежутке существует единственный $E$-оптимальный план
 $$\xi^{*}  = \begin{pmatrix} -r & 0 & r \\ w & 1 -2w & w\end{pmatrix}$$
 где при $r\leq \sqrt{2}$
 $$w = \frac{1}{1+r^4}, \lambda^{*} = \frac{r^4}{4+r^4}$$
 при $r\geq\sqrt{2}$
 $$ w = \frac{r^2 - 1}{2r^4}, \lambda^{*} = \frac{r^2 - 1}{r^2}$$
 \end{thm}
 \begin{proof}
Из теоремы о числе точек получаем, что у нас 2 точки на концах. Из симметрии и единственности получаем, что третья точка должна быть нулем:
Пусть $\xi$ — план с точкой $x \neq 0$. Тогда $\tilde{x}$ план с $x\rightarrow -x$. Рассмотрим $\xi^{*} = \frac{\xi+\tilde{xi}}{2}$. 
$$\lambda_{\min}M(\frac{\xi+\tilde{\xi}}{2}) < \frac{\lambda_{\min}M(\xi) + \lambda_{\min} M(\tilde{\xi})}{2}$$
$$ \begin{pmatrix} m_1 & c \\ c & m_2 \end{pmatrix} + \begin{pmatrix} m_1 & -c \\ -c & m_2 \end{pmatrix}$$
И для суммы в последней строчки мы в прошлой теореме уже выясняли, что максимум когда матрица диагональная. 
Следовательно план симметричный\footnote{В том числе веса на концах совпадают.}. Получаем, что матрица $M(\xi)$ имеет вид:
$$M(\xi) = \begin{pmatrix} 1 & 0 & 2r^2w \\ 0 & 2r^2 w & 0 \\ 2r^2w & 0 & 2wr^4 \end{pmatrix}$$
$$\det (M - \lambda I) = 0$$
$$\det(M-\lambda I) = \left(2r^2 w - \lambda\right)\left(\lambda^2 - \lambda(1 + 2r^4 w)+2r^4w - 4r^4w^2\right)$$
$$\lambda = 2r^2 w$$
$$\lambda(w) = \frac{1 + 2r^4w ± \sqrt{(1+2r^2w)^2 - 8r^4w + 16r^rw^2}}{2}$$
Нам интересно минимальное собственное число и считаем, что в последнем слагаемом минус. Тогда минимум получившегося выражения можно найти с помощью дифференцирования и приравнивания производной к нулю. После этого будет найдено оптимальное $w$\footnote{Надо помнить о том, что $w$ является коэффициентом из выпуклой комбинации и лежит в $[0,1]$. Тем не менее, точки локальных минимумов/максимумов данной функции оказываются хорошими}
Найдя экстремумы относительно $w$ получим\footnote{В репозитории лежит файл для Mathematica, в котором все это считается. На бумажке это считать как-то сложновато}:
$$ w((r^4+4)w - 1) = 0$$
$$w = \frac{1}{r^4 + 4}$$
Решение $w=0$ дает собственное число $\frac{1}{2}$, которое больше, чем $2r^2w$.  
В итоге 
$\lambda = \frac{r^4}{4+r^4}$
Нас интересует минимальное собственное число. Первое собственное число — линейная по $w$ функция. Вторая, как мы видим, сначала возврастает по $w$, а затем убывает. В нуле график прямой лежит ниже, чем график второго собственного числа. Таким образом, если точка $w=\frac{1}{r^4 + 4}$ лежит после пересечения графика $2r^2w$ и 
$\frac{1}{2} \left(2 r^4 w-\sqrt{4 r^8 w^2+16 r^4 w^2-4 r^4 w+1}+1\right)$, то именно она будет точкой плана, в противном случае точкой плана будет пересечение этих графиков.
Точкой пересечения графиков является
$$w=\frac{r^2-1}{2 r^4}, r > 1$$
Откуда можно получить, что для $0 \leq r \leq \sqrt{2}$ решением будет 
$$w=\frac{1}{r^4 + 4}$$
 \end{proof}


 \subsection{Теорема о кратности собственных чисел информационных матриц для полиномиальных моделей}
 \begin{thm}
Пусть $\xi$ — любой невырожденный план. $\lambda_{\min}(M) > 0$. Тогда кратность любого собственного числа информационной матрицы не превосходит двух.
 \end{thm}
 {\color{blue} написать док-во}


 \subsection{Теорема о простоте минимального собственного числа для полиномиальных моделей}
 \begin{thm}
Рассмотрим полиномиальную модель на  $[-1,1]$, $m > 2$. Пусть $\xi$ оптимальный план. Тогда кратность $\lambda_{\min}$ равна 1.
 \end{thm}
{\color{blue} выяснить, было-ли док-во и найти его.}