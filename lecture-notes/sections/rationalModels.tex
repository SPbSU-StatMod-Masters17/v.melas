\section{Дробно-рациональные модели}

{\color{blue} TODO: Разбить на вопросы и дописать}
\subsection{Простейшие дробно-рациональные модели}
Рассмотрим дробно-рациональные модели:
\begin{equation}
\label{rationalModel}
\eta(x, \theta) = \frac{P(x)}{Q(x)} = \frac{\sum\limits_{i=0}^{d_2}p_ix^i}{\sum\limits_{i=0}^{d_1-1}q_ix^i + x^{d_1}}
\end{equation}

Параметр $\theta = (p_0, …, p_{d_2}, q_0, …, q_{d_1-1}\subset \Theta$.

Для корректности этой модели нам требуется ввести несколько ограничений:
\begin{enumerate}
\item При всех $\theta \in \Theta$ дробь \eqref{rationalModel} не сократима. 
\item Знаменатель дроби не обращается в ноль на множестве значений $x$. Будем считать, что $x \in [0,d]$. 
\item $d_2 \geq d_1 - 1$
\end{enumerate}


Приведем несколько примеров:
\begin{ex}
\begin{equation}
\label{rationExm1}
\begin{split}
\eta(x,\theta) &= \frac{\theta_1}{x+\theta_2} = \frac{a}{x+b}\\
f_1(x) &= \frac{\partial}{\partial{a}}\eta(x,\theta) = \frac{1}{x+b}\\
f_2(x) &= \frac{\partial}{\partial{b}} \eta(x,\theta) = -\frac{a}{(x+b)^2} \sim \frac{1}{(x+b)^2}
\end{split}
\end{equation}

Предположим, что число точек в плане совпадает с числом параметров ($n=m$). Значит все веса одинаковы и нам достаточно искать точки $x_1$ и $x_2$ такие, что $\det M(\xi)^2$ будет максимален.
\begin{equation}
\det \begin{pmatrix} \frac{1}{x_1 + b} & \frac{1}{(x_1+b)^2} \\ 
\frac{1}{x_2 + b} & \frac{1}{(x_2 + b)^2}
\end{pmatrix} = \frac{1}{(x_1+b)^2}\frac{1}{(x_2+b)^2}\begin{pmatrix}
x_1 + b & 1 \\ 
x_2 + b & 1 \\
\end{pmatrix}
\end{equation}
\begin{equation*}
\det … \sim \frac{x_2 - x_1}{(x_1+b)^2(x_2+b)^2} (x_1 > x_2)
\end{equation*}

$\sim$ в последнем равенстве означает, что нам достаточно максимизировать данное выражение (мы предполагаем, что $x_1 < x_2$). Пусть $x_1 \neq 0$. Тогда сдвинув на $x_1$ $x_2$ и $x_1$ числитель не поменяется, а знаменатель уменьшится. Значит $x_1 = 0$. Остается решить тривиальную задачу одномерной максимизации\footnote{надеюсь все с этим могут справиться. Можно чуть упростить жизнь, взяв логарифмы.} и получить, что $x_2 = b$.
Отлично, оптимальный план найден.

\end{ex}

\begin{ex}
Приведем еще один пример — модель Михаэлиса-Ментена. Правда эта модель не входит в класс дробно-рациональных.
\begin{equation}
\label{michelMentenModel}
\begin{split}
\eta(x) &= \frac{\theta_1 x}{x+\theta_2} = \frac{ax}{x+b}\\
f_1(x) &= \frac{\partial}{\partial{a}}\eta=\frac{x}{x+b} \\
f_2(x) &= \frac{\partial}{\partial{b}}\eta \sim \frac{x}{(x+b)^2}
\end{split}
\end{equation}

Опять интересуемся максимизацией определителя\footnote{возможно с точностью до знака}:
\begin{equation}
\det F = \begin{pmatrix}
\frac{x_1}{x_1+b} & \frac{x_1}{(x_1+b)^2} \\
\frac{x_2}{x_2+b} & \frac{x_2}{(x_2+b)^2} 
\end{pmatrix}
\end{equation}

\begin{align}
\det … &= \frac{x_1x_2}{(x_1+b)^2(x_2+b)^2}\begin{pmatrix} 
x_1 + b & 1 \\
x_2 + b & 1 \\
\end{pmatrix}\\
\det … &= \frac{(x_2 - x_1) x_1 x_2}{(x_1 + b)^2 (x_2 + b)^2}
\end{align}

Берем производную по $x_2$, получаем, что $x_2 = d$ (по $x_2$ функция будет возрастать).

Теперь ищем максимум:
\begin{equation}
\frac{(d - x_1) x_1 d}{(x_1 + b)^2 (d + b)^2}
\end{equation}
Решение: 
$$x = \frac{bd}{2b + d}$$
\end{ex}


\subsection{Вид определителя информационной матрицы}

\begin{align}
f_i(x) &= \frac{x^{i-1}}{Q(x)}, i =1 … d_2 \\
f_{j}(x) &= \frac{x^{i-1}}{Q(x)^2}P(x), j = 1…(d_1-1)
\end{align}

Пусть $F = \Tr{(f_1, …, f_{2k})}$. Тогда 
\begin{thm}
\begin{equation}
\label{rationModelDet}
\det F = \frac{\prod\limits_{i,j} (x_j - x_i)}{\prod\limits_{i} Q^2(x_i)}
\end{equation}
\end{thm}
\begin{proof}
Умножаем  $i$-ую строчку на $Q^2(x_i)$. После этого медитируем над матрицей и видим, что через второй блок столбцов можно будет убрать $Q(x_i)$ в первом блоке и получить определитель Вандермонда\footnote{может быть придется долго медитировать :)}
\end{proof}

{\color{blue} Дальше есть более подробный факт для частного случая. }

\subsection{Алгебраический подход}
\subsection{Явное нахождение локально-оптимальных планов для дробно-рациональных моделей в виде суммы двух простейших моделей}

{\color{blue} Разбить на 2 билета, если получится}

Теперь мы несколько упростим себе задачу. Пусть $\eta(x, \theta)$ имеет специальный вид:
\begin{equation}
\label{simplRatModel}
\eta(x,\theta) = \sum\limits_{i=1}^{k} \frac{\theta_{2i-1}}{x+\theta_{2i}}, x\in[c,d]
\end{equation}
При этом выполнено $c < \theta_{2i}, i=1…k$. Не умаляя общности, после перепарамметризации можем считать,  что $c=0$. Для этой модели мы хотим построить локально D-оптимальные планы.

Как мы уже выясняли, $D$-оптимальные планы не зависят от линейно-входящих параметров, поэтому их можно после линеаризации брать какими угодно. Мы выберем их равными $-1$ (чтобы дроби были положительны). Теперь как и до этого положим:
\begin{align*}
f_{2i-1}(x) &= \frac{\partial \eta(x, \theta)}{\partial{\theta_{2i-1}}} = \frac{1}{x+\theta_{2i-1}}, i =1 … k \\
f_{2i}(x) &= \frac{\partial \eta(x, \theta)}{\partial{\theta_{2i}}} = \frac{1}{(x+\theta_{2i})^2}, i =1…k\\
\end{align*}

В введенных обозначения справедлива следующая теорема:
\begin{thm}
Для модели \eqref{simplRatModel} при $k=2$ на интервале $[0,d]$ любой локально $D$-оптимальный план имеет четыре опорные точки и одинаковые весовые коэффициенты. Для любых фиксированных $\theta_1…\theta_{2k}$ такой план определяется единственным образом. Кроме того, для достаточно больших интервалов, а именно при 
$$ d \geq \frac{\sqrt{\theta_2\theta_4}}{2}\left(-\frac{\lambda}{2}-1+\sqrt{(\lambda/2 +1)^2 - 4}\right), $$
где $\lambda = -(\theta_2 + \theta_4 + 3) - \sqrt{(\theta_2+\theta_4+3)^2 + 24}$
опорные точки плана равны:
$$ x_1 = 0, x_{2,4} = \frac{\sqrt{\theta_2\theta_4}}{2} \left(-\lambda / 2 - 1 ± \sqrt{(\lambda /2 + 1)^2-4}\right)$$
$$x_3 = \sqrt{\theta_2\theta_4}$$
\end{thm}


Для доказательства данной теоремы нам потребуются промежуточные результаты. Часть из этих результатов — куски предыдущих вопросов. 

\begin{thm}
\label{rationalParamCountThm}
Для дробно-рациональной модели вида \eqref{simplRatModel} для любого $k$ число опорных точек локально $D$-оптимального плана равно числу оцениваемых параметров модели ($2k$).
\end{thm}
\begin{proof}
Пусть 
$$\xi = \begin{pmatrix} x_1 & … & x_n \\ w_1 & … & w_n \end{pmatrix}$$
является локально $D$-оптимальным планом для модели \eqref{simplRatModel}. Как обычно считаем, что точки пронумерованы в порядке возрастания. Тогда по теореме эквивалентности:
\begin{equation}
\begin{split}
\Tr{f(x)}M^{-1}(\xi)f(x) &\leq 2k, x\in[0,d] \\
\Tr{f(x_i)}M^{-1}(\xi)f(x_i) & = 2k
\end{split}
\end{equation}
Обозначим $g(x) = \Tr{f(x)}M^{-1}(\xi)f(x) Q^{4}(x) - 2k Q^{4}(x)$, где 
$$Q(x) = \prod (x+ \theta_{2i})$$
Ясно\footnote{проверяется прямым вычислением — $f_i(x)$ является дробью вида 
$\frac{1}{(x+\theta)^{1 \text{ or } 2}}$}, что $g(x)$ является многочленом степени $4k$. В точках $x_i$, $i=2, …, 2k-1$ у этого многочлена нули второй кратности (т.к. $g(x)$ всегда одного знака по построению), а в $x_1$ и $x_{n}$ нули хотя бы первой кратности. 
Далее, как не раз замечали, $n \geq 2k$, иначе $\det M(\xi) = 0$. 
Пусть $n \geq 2k+1$. В таком случае у $g(x)$ с учетом кратности по крайне мере $2(2k-1) +2 = 4k$ нуля. Далее
если $x_n = d$ и $d$ — нуль кратности один, то $g(d+\varepsilon) > 0$ в некоторой окрестности точки $d$, а при 
$x\Rightarrow \infty$ $g(x) \sim -2kx^{4k}$, а значит существует $x_{n+1}$ $g(x_{n+1}) = 0$. Значит у $g(x)$ с учетом кратности не менее $4k+1$ нулей. Следовательно $g$ тождественный ноль. Противоречие (по теореме эквивалентности Крамера-Вольда максимум достигается только на точках плана). 
\end{proof}

Следствием теоремы \eqref{rationalParamCountThm} является то, что у оптимального плана все веса одинаковы (мы это уже выясняли) и задачи максимизации сводится к поиску максимума $(\det F)^2$.

{\color{blue} Тут будет примерно тоже самое, что было в небольшом куске про определитель до этого.}
Рассмотрим матрицу $G = \{ \frac{1}{x_i + b_j}\}_{i,j = 1}^{2k}$. 
\begin{thm}
Для любых вещественных $x_1, …, x_{2k}, b_1,…, b_{2k}$
$$\det G = \frac{\prod\limits_{j>i} (x_j-x_i) \prod\limits_{j>i}(b_j - b_i)}{\prod\limits_i\prod\limits_j (x_i + b_j)}$$
\end{thm}
\begin{proof}
Умножим $i$-ую строчку на $\prod\limits_{j=1}^{2k}(x_i+b_j)$. 
\begin{equation}
\begin{split}
G_1 = (\prod\limits_{i=1}^{2k}\prod\limits_{j=1}^{2k}(x_i+b_j)) \det G \\
G_1 = \det\left( \prod\limits_{j\neq 1} (x_i-b_j), …, \prod\limits_{j\neq 2k} (x_i-b_j)\right)_{i=1}^{2k}\\
\end{split}
\end{equation}
Вычтем первый столбце из остальных и получим
$$G_1 = \det\left( \prod\limits_{j\neq 1} (x_i-b_j),\prod\limits_{j\neq 1,2} (x_i-b_j) (b_2 - b_1) …, \prod\limits_{j\neq 1, 2k} (x_i-b_j) (b_{2k} - b_1)\right)_{i=1}^{2k}$$
вынесем $(b_j-b_1)$ из всех столбцов столбцов и повторим операцию, вычитая второй столбец из третьего и т.д. Получим:
$$G_1 = \prod\limits_{j>i}(b_j - b_i) \det \left(\prod(j\neq 1)(x_i - b_j), \prod\limits_{j\neq 1,2}(x_i-b_j),…,1\right)$$ 
Далее у нас каждый столбец — почти $x^j$, но с некоторыми плохими коэффициентами. Приводим его линейными преобразованиями к стандартному:
$$G_1 - \prod \limits_{j>i}(b_j - b_i) \det(x_i^{2k-1}, x_i^{2k-2},…, x_i,1)$$
Получаем определитель Вандермонда, что и требовалось.
\end{proof}

Теперь получим формулу для определителя $F$.
\begin{thm}
\begin{equation}
\label{detEquatin}
\det F = \frac{\prod\limits_{j>i}(\theta_{2i}-\theta_{2j})\prod\limits_{j>i}(x_j - x_i)}{\prod\limits_i\prod\limits_j (x_i + \theta_{2j})^2}
\end{equation}
\end{thm}

\begin{proof}
$$ \frac{1}{(x + \theta_{2i})^2} = \lim\limits_{\delta \rightarrow 0} \frac{1}{\delta}\left(\frac{1}{x+\theta_{2i}+\delta} - \frac{1}{x+\theta_{2i}}\right)$$
$$\det F = \det \left(\frac{1}{x_i + \theta_2}, \frac{1}{(x_i \theta_2)^2}, …, \frac{1}{x_i+\theta_{2k}}, \frac{1}{(x_i + \theta_{2k})^2} \right)_{i=1}^{2k}$$
$$ \det F = \lim \limits_{\delta \rightarrow 0} \frac{1}{\delta^k} \det \left(\frac{1}{x_i + \theta_2}, \frac{1}{x+\theta_{2i}+\delta} - \frac{1}{x+\theta_{2i}}, … \right)_{i=1}^{2k}$$
$$\det F = \lim \limits_{\delta \rightarrow 0} \frac{1}{\delta^k}\det \left( \frac{1}{x_i + b_j} \right)_{i,j=1}^{2k}$$
Складываем соседние столбцы, применяем прошлую теорему и получаем требуемое.
\end{proof}

\subsection{Дифференцирование уравнения и его алгебраической формы}

\begin{thm}
Пусть $0 \leq x_1 < … < x_k$ — опорные точки локально $D$-оптимального плана для модели \eqref{simplRatModel}.  Тогда $x_1 = 0$.
\end{thm}
\begin{proof}
Рассмотрим формулу \eqref{detEquatin}. Если из всех $x_i$ вычесть некоторое $\delta \in (0, x_1)$, то числитель не изменится, а знаменатель уменьшится. Значит $x_1 = 0$, т.к. мы ищем оптимальный план, а если $x_1 >0$, то определитель можно увеличить.
\end{proof}

Итого, задачу поиска оптимального плана мы свели к поиску максимума следующей функции\footnote{здесь на один $x_i$ меньше}:
\begin{equation}
\label{targetEq}
\frac{\prod\limits_{j>i}(x_j - x_i) \prod x_i}{\prod\limits_i\prod\limits_j (x_i + \theta_{2j})^2}
\end{equation}

Обозначим многочлен $\prod\limits_{i=2}^{2k}(x-x_i)$ за $\psi(x)$, а коэффициенты многочлена будем обозначать за $\psi_0, …, \psi_{2k-1}$:
$$\psi(x) = \sum\limits_{i=0}^{2k-2}\psi_i x^{2k-i-1}, \psi_0 = 1$$

Пусть в оптимальном плане $x_{2k} < d$\footnote{случай $x_{2k}=d$ рассматривается аналогично}. По необходимому условию экстремума частные производные   функции \eqref{targetEq} обращаются в ноль на оптимальном плане:
$$ \frac{1}{x_i} + \sum\limits_{i\neq j} \frac{1}{x_j- x_i} - 2 \frac{Q'(x_i)}{Q(x_i)} = 0$$
где $Q(x)= \prod(x+\theta_{2i}$ 

Воспользуемся следующим равенством\footnote{интересно, получается ли оно каким-нибудь естественным образом…}:
$$\frac{1}{2} \sum\limits_{j\neq i}\frac{1}{x_i - x_j} = \frac{\psi''(x)}{\psi'(x)}|_{x=x_i}$$
Умножим предпоследнее неравенство на $\Psi'(x) x Q(x)$ и получим:
$$ h(x) = \Psi''(x) xQ(x) + 2 \Psi'(x)\left(Q(x) - 2xQ'(x)\right)$$
Многочлен $h(x)$ обращатся в ноль в точках $x_2…x_{2k}$. Следовательно, этот многочлен имеет вид $\psi(x)\lambda(x)$. Его нули содержат нули $\psi(x)$, а т.к. это многочлен, то оставшиеся нули содержатся в многочлене $\lambda(x)$, имеющем вид:
$$ \lambda(x) = \sum\limits_{i=0}^{k-1}\lambda_ix^i$$
Степень $h(x)$ легко считается: $(2k-4) + k + 1 = 3k-3$, $3k-3 - (2k-2) = k -1$.
В итоге получили уравнение:
\begin{equation}
\label{targetEq2}
\psi''(x)xQ(x) + 2 \psi'(x)\left(Q(x) - xQ'(x)\right) = \lambda(x)\psi(x)
\end{equation}

\begin{thm}
Пусть $\phi(x) = \Tr{(x^n, x^{n-1},…,1)}$. Существует матрица $A_1$ такая, что 
\begin{equation}
\label{derEq}
\Tr{\phi(x)}A_1 = \Tr{(\phi'(x))}
\end{equation}
\end{thm}
\begin{proof}
$$ \sum a_{ij} x^{n+1-i} = (n+1-j)x^{n-j}, j=1…n$$
Значит $a_{i,i-1} = n+2-i$ для $i=2…n+1$, а остальные $a_{ij} = 0$.
\end{proof}
\begin{thm}
Пусть $\phi(x) = \Tr{(x^n, x^{n-1},…,1)}$. Существует матрица $A_1$ такая, что 
\begin{equation}
\label{derEq2}
\Tr{\phi(x)}A_2 = \Tr{(\phi''(x))}
\end{equation}
\end{thm}
\begin{proof}
Аналогично предыдущему
\end{proof}

Теперь пусть $\lambda(x) = \sum\limits_{i=0}^{s} \lambda_i x^{s-i}$, $\tilde{\phi}(x) = \Tr{(x^{s+n}, …, 1)}$. Тогда  существует такая $C_\lambda$, что 
$$\Tr{\tilde{\phi}(x)}C_\lambda = \lambda(x) \Tr{\phi(x)}, \text{ где}$$
$$\phi(x) = \Tr{(x^n, x^{n-1},…,1)}$$
Доказывается аналогично леммам и получается, что:
$$ C_\lambda = \sum\limits_{i=0}^{s} \lambda_i E_i, \text{ где }$$
$$\Tr{E_0} = (I_{n+1}O_s), \Tr{E_s}=(0_1I_{n+1})_{s-1}), …,\Tr{E_s}=(0_sI_{n+1})$$ 

После введенных обозначений \eqref{targetEq2} можно записать в форме:
\begin{equation}
\Tr{\phi(x)} A\psi = \Tr{\phi}C_\lambda\psi
\end{equation}
где $\Tr{\phi(x)} = (x^{n+k-1},…,1)$, а $\lambda(x) = \sum\limits_{i=0}^{k-1}\lambda_i x^{k-i-1}$.

В случае $k=2$ и достаточно больших $d$ это уравнение удается решить в явном виде. Этим мы и займемся в следующем разделе.
\subsection{Явное нахождение локально-оптимальных планов…}

Рассмотрим модель \eqref{simplRatModel} при $k=2$. Мы свели задачу к нахождению максимума функции
\begin{equation}
\frac{\prod\limits_{2\leq i < j \leq 4} (x_j - x_i) \prod\limits_{i=2}^4x_i}{\prod\limits_{i=2}^{2k}Q^2(x_i)}
\end{equation}
где  
$$Q(x) = (x+\theta_2)(x+\theta_4) = x^2 + ax + b$$
$$ a= \theta_2 + \theta_4, b = \theta_2\theta_4$$
Обозначим $\tilde{x} = \frac{x}{\sqrt{b}}$, $\tilde{a} = \frac{a}{\sqrt{b}}$. Тогда 
$$ Q(\tilde{x}) = b(\tilde{x} + \tilde{a}\tilde{x} + 1)$$
Заметим, что после замены $x \rightarrow \tilde{x}$  $b$ сокращается. Следовательно можно считать, что $b=1$ и опускать знак волны.  В таком случае уравнение \eqref{targetEq2} принимает вид:
\begin{equation}
(6x + 2 \psi_{1})x(x^2 + ax + 1) + 2(3x^2 + 2\psi_1 x + \psi_2) (-3x^2 - ax +1) = (\lambda_0 x + \lambda_1)(x^2 + \psi_1x^2+\psi_2 x + \psi_3)
\end{equation}

После приведения членов в левой части получаем следующую (матричную запись):
\begin{equation}
(x^4 x^3 x^2 x 1) \begin{pmatrix} -12 & 0 & 0 & 0 \\ 0 & -10 & 0 & 0 \\ 12 & -2a & -6 & 0 \\ 0 & 6 & -2a & 0 \\ 0 & 0 & 2 & 0 \end{pmatrix}  \begin{pmatrix} 1 \\ \psi_1 \\ \psi_2 \\ \psi_3 \end{pmatrix}
\end{equation}

В правой части:
$$ \lambda(x) \psi(x) = (x^4 x^3 x^2 x 1) C_\lambda \psi, \text{ где }$$
\begin{equation}
C_\lambda = \lambda_0 \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 &0\\ 0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 0 \end{pmatrix} + \lambda_1 \begin{pmatrix} 0 & 0 & 0 & 0  \\ 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 &0\\ 0 & 0 & 0 & 1\end{pmatrix}
\end{equation}
Приравняв коэффициенты при $x^4$ получаем, что $\lambda_0 = -12$
Остается уравнение на $\lambda_1$. Перенеся (в матричном виде) все слагаемые в одну часть получаем уравнение
$$(A-\lambda_0E_0 - \lambda_1E_1)\psi = 0$$
В матрице первая строчка равна нулю, поэтому вычеркнув ее уравенение сводится к
$$\det (B-\lambda I) = 0$$
$$B - \lambda I = \begin{pmatrix} -\lambda & -2 & 0 & 0 \\ 12 & -2a - \lambda & 6 & 0 \\ 0 & 6 & -2a - \lambda & 12 \\ 0 & 0 & 2 & -\lambda \end{pmatrix}$$
Определитель равен\footnote{интересно, что это за способ вычисления определителя…}:
\begin{equation}
\begin{split}
\det (B-\lambda I) = &\det \begin{pmatrix} -\lambda & -2 \\ 12 & -2a - \lambda \end{pmatrix}\det\begin{pmatrix}
-2a - \lambda & 12 \\ 2 & -\lambda\end{pmatrix} - \\
&\det \begin{pmatrix} -\lambda & 0 \\ 12 & 6 \end{pmatrix} \det \begin{pmatrix} 6 & 12 \\ 0 & -\lambda \end{pmatrix}=\\
& (\lambda(2a+\lambda) - 24)^2 - 36 \lambda^2 
\end{split}
\end{equation}

Получили уравнение и возможные решения:
\begin{equation}
\begin{split}
&(\lambda^2 - (2a-6)\lambda - 24)(\lambda^2 + (2a+6) - 24) = 0\\
&\lambda  = -(a+3) ± \sqrt{(a+3)^2 + 24}\\
&\lambda = -(a-3) ± \sqrt{(a-3)^2 + 23}\\
\end{split}
\end{equation} 

Далее вектор $\psi$ является решением
\begin{equation}
\label{psieq}
\begin{pmatrix} 0 & 2 & 0 & 0 \\ 12 & -2a & 6 & 0 \\ 0 & 6 & -2a & 12 \\ 0 & 0 & 2 & 0 \end{pmatrix}\begin{pmatrix} 1 \\ \psi_1 \\ \psi_2 \\ \psi_3 \end{pmatrix} = \lambda_1 \begin{pmatrix} 1 \\ \psi_1 \\ \psi_2 \\ \psi_3 \end{pmatrix} 
\end{equation}
При этом $\psi$ задает многочлен с положительными корнями, за счет чего получаем, что $\psi_1 < 0$ $\psi_2 > 0$, $\psi_3 < 0$. 
$$ \psi_1 = -x_2 - x_3 - x_4$$
$$ \psi_2 = x_2 x_3 + x_3 x_4 x_2x_4$$
$$\psi_3 = -x_2x_3x_4$$

Смотрим на уравнение \eqref{psieq} и получаем:
$$ 2 \psi_1 = \lambda_1 \Rightarrow \psi_1 = \frac{\lambda_1}{2}$$
$$12 - 2a\psi_1 + 6\psi_2 = \lambda_1 \psi_1 \Rightarrow$$
$$12 - a\lambda_1+6\psi_2 = \frac{\lambda_1^2}{2}$$
$$\lambda_1^2 + 2a\lambda_1 - 12\psi_2 - 24 = 0$$
Далее 
$$\lambda_1^2 - (2a±6)\lambda_1 - 24 = 0$$
Вычитаем из из предыдущего, пользуемся тем, что $\psi_2 < 0$ и получаем:
$$\lambda_1 < 0$$
$$ \psi_2 = -\frac{\lambda_1}{2}$$
Далее последнее уравнение дает 
$$2\psi_2 = \lambda_1 \psi_3$$
$$\psi_3 = -1$$
Теперь пользуемся тем, что $\lambda_1 <0$ и $\sqrt{(a+3)^2 +21} > |a+3|$ получаем, что единственное возможно решение для $\lambda_1$:
$$\lambda_1 = -(a+3)-\sqrt{(a+3)^2+24}$$
Следовательно:
$$\psi(x) = x^3 + \frac{\lambda_1}{2}x^2 - \frac{\lambda_1}{2}-1 = \left(x-1\right)\left(x^2 + x(1+\frac{\lambda_1}{2}) + 1\right)$$
Корни последнего уравнения — точки оптимального плана. Решив его получаем, что 
$$x_3 = 1$$
$$x_{4,2} = \frac{1}{2}\left(-\left(1+\frac{\lambda_1}{2}\right) ± \sqrt{\left(1+\frac{\lambda_1}{2}\right)^2-4}\right)$$ 
Теорема доказана.
